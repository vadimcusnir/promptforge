---
description: OpenAI runtime — retries, backoff, cost estimate, token budgeting.
globs:
  - "lib/ai/**"
alwaysApply: false
---

# 22-openai-runtime.mdc — OpenAI Integration

## Model Configuration

### Primary Models
- **Editor**: GPT-4o, temperature=0.3, max_tokens=2000
- **Test Engine**: GPT-4o, temperature=0.2, max_tokens=1000  
- **Evaluator**: GPT-4o, temperature=0.1, max_tokens=500
- **Generation**: GPT-4o/GPT-5, temperature=0.4, dynamic max_tokens

### Model Selection Logic
```typescript
interface ModelConfig {
  name: string;
  temperature: number;
  max_tokens: number;
  cost_per_1k_tokens: number;
}

function selectModel(context: {
  operation: "generate" | "edit" | "test" | "evaluate";
  complexity: "foundational" | "standard" | "advanced" | "expert";
  urgency: "low" | "planned" | "sprint" | "pilot" | "crisis";
}): ModelConfig {
  if (context.operation === "evaluate") {
    return { name: "gpt-4o", temperature: 0.1, max_tokens: 500, cost_per_1k_tokens: 0.03 };
  }
  
  if (context.urgency === "crisis") {
    return { name: "gpt-4o", temperature: 0.2, max_tokens: 3000, cost_per_1k_tokens: 0.03 };
  }
  
  if (context.complexity === "expert") {
    return { name: "gpt-5-thinking", temperature: 0.4, max_tokens: 4000, cost_per_1k_tokens: 0.06 };
  }
  
  return { name: "gpt-4o", temperature: 0.4, max_tokens: 2000, cost_per_1k_tokens: 0.03 };
}
```

## Retry Logic & Error Handling

### Exponential Backoff
```typescript
interface RetryConfig {
  maxRetries: number;
  baseDelay: number;
  maxDelay: number;
  jitter: boolean;
}

const DEFAULT_RETRY: RetryConfig = {
  maxRetries: 3,
  baseDelay: 1000,    // 1 second
  maxDelay: 30000,    // 30 seconds
  jitter: true
};

async function withRetry<T>(
  operation: () => Promise<T>, 
  config: RetryConfig = DEFAULT_RETRY
): Promise<T> {
  let lastError: Error;
  
  for (let attempt = 0; attempt <= config.maxRetries; attempt++) {
    try {
      return await operation();
    } catch (error) {
      lastError = error;
      
      if (attempt === config.maxRetries) break;
      
      // Don't retry on certain errors
      if (isNonRetryableError(error)) break;
      
      const delay = calculateBackoffDelay(attempt, config);
      await sleep(delay);
    }
  }
  
  throw lastError;
}
```

### Error Classification
```typescript
function isNonRetryableError(error: any): boolean {
  // OpenAI specific error codes
  if (error.status === 400) return true;  // Bad request
  if (error.status === 401) return true;  // Invalid API key
  if (error.status === 403) return true;  // Forbidden
  if (error.status === 404) return true;  // Model not found
  
  // Content policy violations
  if (error.code === 'content_policy_violation') return true;
  
  // Retryable errors: 429 (rate limit), 500+ (server errors)
  return false;
}
```

## Cost Tracking & Budgeting

### Token Usage Tracking
```typescript
interface TokenUsage {
  prompt_tokens: number;
  completion_tokens: number;
  total_tokens: number;
  estimated_cost_usd: number;
  model: string;
  cached: boolean;
}

function calculateCost(usage: TokenUsage, model: string): number {
  const pricing = MODEL_PRICING[model];
  if (!pricing) throw new Error(`Unknown model: ${model}`);
  
  const promptCost = (usage.prompt_tokens / 1000) * pricing.prompt_per_1k;
  const completionCost = (usage.completion_tokens / 1000) * pricing.completion_per_1k;
  
  return promptCost + completionCost;
}
```

### Budget Controls
```typescript
interface BudgetLimits {
  daily_limit_usd: number;
  monthly_limit_usd: number;
  per_request_limit_usd: number;
}

async function checkBudget(org_id: string, estimated_cost: number): Promise<void> {
  const limits = await getBudgetLimits(org_id);
  const usage = await getCurrentUsage(org_id);
  
  // Check per-request limit
  if (estimated_cost > limits.per_request_limit_usd) {
    throw new BudgetExceededError("Per-request limit exceeded");
  }
  
  // Check daily limit
  if (usage.daily_cost + estimated_cost > limits.daily_limit_usd) {
    throw new BudgetExceededError("Daily budget exceeded");
  }
  
  // Check monthly limit
  if (usage.monthly_cost + estimated_cost > limits.monthly_limit_usd) {
    throw new BudgetExceededError("Monthly budget exceeded");
  }
}
```

## Prompt Engineering Best Practices

### System Message Templates
```typescript
const SYSTEM_TEMPLATES = {
  generator: `You are a professional prompt engineer. Generate clear, executable prompts based on the 7D parameters provided. Follow the PROMPTFORGE™ structure: Context → Requirements → Specification → KPI → Guardrails → Fallback → Output Format.`,
  
  editor: `You are an expert prompt optimizer. Improve the given prompt for {action}. Maintain the core intent while enhancing clarity and execution readiness.`,
  
  evaluator: `You are a strict prompt evaluator. Score the prompt on 0-100 scale for: Clarity, Execution Readiness, Ambiguity (lower=better), Business Fit. Be precise and constructive.`,
  
  crisis: `CRISIS MODE: Generate an emergency-ready prompt with zero ambiguity. Include immediate action steps, escalation paths, and risk mitigation. Prioritize speed and clarity over elegance.`
};
```

### Domain-Specific Instructions
```typescript
function getDomainInstructions(domain: string): string {
  const instructions = {
    fintech: "Ensure SEC/FCA compliance. No unverified financial claims. Include appropriate disclaimers.",
    healthcare: "Follow HIPAA guidelines. No diagnostic advice. Recommend professional consultation.",
    legal: "Provide information only, not legal advice. Include jurisdiction disclaimers.",
    education: "Ensure age-appropriate content. Respect academic integrity guidelines."
  };
  
  return instructions[domain] || "";
}
```

## Rate Limiting & Queuing

### Request Queuing
```typescript
interface QueueConfig {
  maxConcurrent: number;
  timeoutMs: number;
  priority: "low" | "normal" | "high" | "critical";
}

class OpenAIQueue {
  private queue: Array<{
    request: () => Promise<any>;
    priority: number;
    resolve: (value: any) => void;
    reject: (error: any) => void;
  }> = [];
  
  private running = 0;
  
  async enqueue<T>(
    request: () => Promise<T>, 
    config: QueueConfig
  ): Promise<T> {
    return new Promise((resolve, reject) => {
      const priorityValue = this.getPriorityValue(config.priority);
      
      this.queue.push({ request, priority: priorityValue, resolve, reject });
      this.queue.sort((a, b) => b.priority - a.priority);
      
      this.processQueue(config);
    });
  }
  
  private async processQueue(config: QueueConfig) {
    if (this.running >= config.maxConcurrent || this.queue.length === 0) {
      return;
    }
    
    this.running++;
    const item = this.queue.shift()!;
    
    try {
      const result = await Promise.race([
        item.request(),
        this.timeout(config.timeoutMs)
      ]);
      item.resolve(result);
    } catch (error) {
      item.reject(error);
    } finally {
      this.running--;
      this.processQueue(config);
    }
  }
}
```

## Monitoring & Observability

### Performance Metrics
```typescript
interface OpenAIMetrics {
  total_requests: number;
  successful_requests: number;
  failed_requests: number;
  average_latency_ms: number;
  total_tokens_used: number;
  total_cost_usd: number;
  error_rate: number;
  cache_hit_rate: number;
}

async function logOpenAIMetrics(
  operation: string,
  model: string,
  usage: TokenUsage,
  latency_ms: number,
  success: boolean
) {
  await supabase.from("ai_metrics").insert({
    operation,
    model,
    tokens_used: usage.total_tokens,
    cost_usd: usage.estimated_cost_usd,
    latency_ms,
    success,
    cached: usage.cached,
    timestamp: new Date()
  });
}
```

### Alert Thresholds
- **Error rate** > 5% în ultimele 15 minute
- **Average latency** > 10 secunde
- **Cost spike** > 50% față de baseline
- **Token usage** > budget threshold
- **Model deprecation** warnings